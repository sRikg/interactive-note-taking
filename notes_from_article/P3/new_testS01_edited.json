"<pad> dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. we propose a new simple network architecture, the Transformer, based solely on attention mechanisms. our model achieves 28.4 BLEU on the WMT 2014 english-to-German translation task. our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs </s>"