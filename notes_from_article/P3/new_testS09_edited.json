"<pad> each layer in our encoder and decoder contains a fully connected feed-forward network. this consists of two linear transformations with a ReLU activation in between. the dimensionality of input and output is d_(model) = 512, and the inner-layer has dimensionality d_(ff) = 2048. in our model we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation.</s>"