"<pad> dropout can be interpreted as a way of regularizing a neural network by adding noise to the hidden units. our method can be applied to other neuron-based architectures, for example,boltzmann machines. dropout can be seen as a way of regularizing a neural network by addingnoise to the hidden units. our method can be interpreted as a form of modelaveraging and can be extended to supervisedlearning problems - daniel schmidt. a a a</s>"