"<pad> the word2vec model performs significantly better than the other baselines, often with smaller vector sizes and smaller corpora. the model can easily be trained on a large 42 billion token corpus, with a substantial corresponding performance boost<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n<unk> n </s>"