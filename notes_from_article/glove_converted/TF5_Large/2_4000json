"<pad> ning not the scalar distance between word vec- tors, but rather their various dimensions of dif- ference. currently, both main model families for learning word vectors suffer sig- nificant drawbacks. we propose a spe- cific weighted least squares model that trains on global word-word co-occurrence counts. the model produces a word vector space with meaningful sub- structure, as evidenced by its state-of-the-art per- a- a</s>"