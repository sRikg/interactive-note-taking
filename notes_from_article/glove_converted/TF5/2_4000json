"<pad> ning not the scalar distance between word vec- tors, but rather their various dimensions of dif- ference. the two main model families for learning word vectors are: global matrix factorization and local context window methods. while methods like LSA ef- ficiently leverage statistical information, they do relatively poorly on the word analogy task. while methods like skip-gram model of Mikolov et al. (2013c) do relatively poorly on the word analogy task - a a</s>"