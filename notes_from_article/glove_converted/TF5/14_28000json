"<pad> a total of 437,905 discrete features were generated for the CoNLL- 2003 training dataset. 50-dimensional vectors for each word of a five-word context are added and used as continuous features. we trained our model on five corpora of varying sizes: a 2010 Wikipedia dump with 1 billion to- kens; a 2014 Wikipedia dump with 1.6 billion to- kens; Gigaword 5 which has 4.3 billion tokens<unk> n<unk> nthe analogy task.. a </s>"