"<pad> extra columns can contribute a disproportion- ate number of zero entries. GloVe model performs significantly better than the other baselines, often with smaller vector sizes and smaller corpora. many weighting schemes like PPMI destroy the sparsity of X and therefore cannot feasibly be used with large vocabularies. results show that the model can easily be trained on a large 42 billion token corpus, with a substantial corresponding performance boost. <unk> n<unk> n\u00ad\u00ad\u00ad\u00ad\u00ad</s>"