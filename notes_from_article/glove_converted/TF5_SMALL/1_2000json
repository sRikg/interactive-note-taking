"<pad> recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities. a new global log- bilinear regression model combines the advantages of the two major model families in the literature. the model pro- duces a vector space with meaningful sub- structure, as evidenced by its performance of 75% on a recent word analogy task. it also outperforms related models on simi- larity tasks and named entity recognition...  </s>"