"<pad> we use a comprehensive set of discrete features that comes with the standard distribution of the Stanford NER model. a total of 437,905 discrete features were generated for the CoNLL- 2003 training dataset. we tokenize and lowercase each corpus with the Stanford to- kenizer, build a vocabulary of the 400,000 most frequent words6, and then construct a matrix of co- occurrence counts. we train the model with exactly the same setup as the CRFjoin model of (Wang - gra- </s>"