"<pad> many current NLP systems treat words as atomic units - there is no notion of similarity between words. simple models trained on huge amounts of data outperform complex systems trained on less data. with progress of machine learning techniques in recent years, it has become possible to train more complex models on much larger data set. distributed representations of words can be used to train more complex models on much larger data set, and they typically outperform the simple models.</s>"