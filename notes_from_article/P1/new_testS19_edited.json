"<pad> in this paper we studied the quality of vector representations of words derived by various models on a collection of syntactic and semantic language tasks. because of the much lower computational complexity, it is possible to compute very accurate high dimensional word vectors from a much larger data set. using the distbelief distributed framework, it should be possible to train the CBOW and skip-gram models even on corpora with one trillion words.</s>"