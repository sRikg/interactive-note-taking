"<pad> a feedforward neural network with a linear projection layer and a non-linear hidden layer was used to learn jointly the word vector representation and a statistical language model. another interesting architecture of NNLM was presented in [13, 14], where the word vectors are first learned using neural network with a single hidden layer. in this work, we directly extend this architecture, and focus just on the first step where the word vectors are learned using a simple model. the word vectors can be used to significantly improve a a a a a a a a a a a a a a a a a a a a a a a a a ena a a a a a a a a a a a a a a a a </s>"