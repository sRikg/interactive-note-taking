"<pad> recurrent neural network based language model has been proposed to overcome certain limitations of the feedforward NNLM. the RNN model does not have a projection layer only input, hidden and output layer. the complexity per training example of the RNN model is -- ----------------------- -- ----- where the word representations D have the same dimensionality as the hidden layer H. theoretically RNNs can efficiently represent more complex patterns than the shallow neural networks.</s>"