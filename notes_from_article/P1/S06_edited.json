"<pad> probabilistic feedforward neural network language model consists of input, projection, hidden and output layers. as only inputs are active at any given time, composition of the projection layer is relatively cheap operation. the hidden layer is used to compute probability distribution over all the words in the vocabulary, resulting in an output layer with dimensionality. with binary tree representations of the vocabulary, the number of output units that need to be evaluated can go down to around log2(V) thus most of the complexity is caused by the term N.......................... to ena re-a a a re a s a...... en.</s>"