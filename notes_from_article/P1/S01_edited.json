"<pad> we propose two novel model architectures for computing continuous vector representations of words from very large data sets. the quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques. we observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. our vectors provide state-of-the-art performance on our test set for measuring syn a a a a a a a a a a a.... a..... a. a.. a. a.... a. a. a.-of-e -a.</s>"