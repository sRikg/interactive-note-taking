"<pad> <unk> nIncreasing amount of training data twice results in about the same increase of computational complexity as increasing vector size twice. <unk> nfor the experiments reported in Tables 2 and 4, we used three training epochs with stochastic gradi- ent descent and backpropagation. we compare different model architectures for deriving the word vectors using the same training data and using the same dimensionality of 640 of the word vectors. in the further experiments, we use full set of questions in a a a</s>"