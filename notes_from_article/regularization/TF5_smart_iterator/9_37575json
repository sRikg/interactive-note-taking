"<pad> we propose theweight-dropped LSTM, a strategy that uses a DropConnectmask on the hidden-to-hidden weightmatrices. we further investigate the use of averaged SGD with a non-monontonic trigger for training language models. our mod-els outperform custom-built RNN cells and complex reg-ularization strategies that preclude the possibility of using NVIDIA cuDNN LSTM. our models outperform custom-built RNN cells and complex reg- a a </s>"