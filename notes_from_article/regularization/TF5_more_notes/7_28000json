"<pad> pointer based attention models have been shown to be highly effective in improving language mod-eling (Merity et al., 2016; Grave et al., 2016). pointer based attention models may be complementary and would beworth exploring. LSTM <unk> <unk> 82.3Grave et al. (2016) - LSTM + continuous cache pointer <unk> <unk> 82.3Grave et al. (2016) - LSTM + continuous cache pointer <unk> <extra_id_27> a a</s>"