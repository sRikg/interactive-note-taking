"<pad> we reversed the order of words in the source sentence but not the target sentences. this trick is one of the keytechnical contributions of this work. a recurrent neural network (RNN) can easily map sequences to sequences. but it is not clear how to apply an RNN to problems whose input and output sequences have different lengths with complicated and non-monotonic relation-ships. the simplest strategy for general sequence learning is to map the input sequence to a fixed- a a a</s>"