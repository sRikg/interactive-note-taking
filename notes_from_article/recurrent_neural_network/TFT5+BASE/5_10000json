"<pad> starting learning rate is <unk> = 0.1. After each epoch, the network is tested on validation data. if no significant improvement is observed, learning rate <unk> is halved at start of each new epoch. in our experiments, networks do not overtrain significantly, history is represented by hypothesis given by recognizer, and contains recognition errors. to overcome this sim- plity, backpropagation through time (BPTT) algorithm is commonly used (see Boden [5] for details) a a a</s>"