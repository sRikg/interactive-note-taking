"<pad> time needed to train optimal network increases faster than just linearly with increased amount of training data. in some experiments we have achieved almost twice perplexity reduction over n-gram models by using a recurrent network instead of a feedforward network. for comparison, it takes around 6 hours for our basic implementation to train RNN model based on brown corpus (800K words, 100 hidden units and vocab- ulary threshold 5). for comparison, it takes around 6 hours for our basic implementation to train RNN<extra_id_27> a a </s>"