"<pad> sult was 112. All LMs in the preceding experiments were trained on only 6.4M words. results are reported in Table 3, and we can conclude that RNN based models can reduce WER by around 12% relative, com- pared to backoff model trained on 5x more data. we experimented with lattices generated by AMI system used for NIST RT05 evaluation on independent headset condition. test data set was 37M or 70M words used for training baseline backoff.. a</s>"