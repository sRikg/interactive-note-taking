"<pad> sult was 112. All LMs in the preceding experiments were trained on only 6.4M words. to provide a comparison with Xu [8] and Filimonov [9], we have used 37M words based backoff model (the same data were used by Xu, Filimonov used 70M words) to conclude that RNN based models can reduce WER by around 12% relatively, com- pared to backoff model trained on 5x more data3....</s>"