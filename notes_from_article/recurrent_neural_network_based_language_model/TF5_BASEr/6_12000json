"<pad> in some experiments we have achieved almost twice perplexity reduction over n-gram models by using a recurrent network instead of a feedforward network. it takes around 6 hours for our basic implementation to train RNN model based on brown corpus (800K words, 100 hidden units and vocab- ulary threshold 5) WSJ experiments To evaluate performance of simple recurrent neural network based language model, we have selected several standard speech recognition tasks. the training corpus consists of 37M words<extra_id_27> - - a</s>"