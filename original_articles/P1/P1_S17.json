The Microsoft Sentence Completion Challenge has been recently introduced as a task for advancing language modeling and other NLP techniques\u00a0[32]. This task consists of 1040 sentences, where one word is missing in each sentence and the goal is to select word that is the most coherent with the rest of the sentence, given a list of five reasonable choices. Performance of several techniques has been already reported on this set, including N-gram models, LSA-based model\u00a0[32], log-bilinear model\u00a0[24] and a combination of recurrent neural networks that currently holds the state of the art performance of 55.4% accuracy on this benchmark\u00a0[19].  We have explored the performance of Skip-gram architecture on this task. First, we train the 640-dimensional model on 50M words provided in\u00a0[32]. Then, we compute score of each sentence in the test set by using the unknown word at the input, and predict all surrounding words in a sentence. The final sentence score is then the sum of these individual predictions. Using the sentence scores, we choose the most likely sentence.  A short summary of some previous results together with the new results is presented in Table\u00a07. While the Skip-gram model itself does not perform on this task better than LSA similarity, the scores from this model are complementary to scores obtained with RNNLMs, and a weighted combination leads to a new state of the art result 58.9% accuracy (59.2% on the development part of the set and 58.7% on the test part of the set).  Table 7: Comparison and combination of models on the Microsoft Sentence Completion Challenge.  Architecture Accuracy [%] 4-gram\u00a0[32] 39 Average LSA similarity\u00a0[32] 49 Log-bilinear model\u00a0[24] 54.8 RNNLMs\u00a0[19] 55.4 Skip-gram 48.0 Skip-gram + RNNLMs 58.9