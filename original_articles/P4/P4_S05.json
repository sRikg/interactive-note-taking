In addition to the regularization and optimization techniques above, we explored additional regularization techniques that aimed to improve data efficiency during training and to prevent overfitting of the RNN model. 
4.1 Variable length backpropagation sequences 
Given a fixed sequence length that is used to break a data set into fixed length batches, the data set is not efficiently used. To illustrate this, imagine being given 100 elements to perform backpropagation through with a fixed backpropagation through time (BPTT) window of 10. Any element divisible by 10 will never have any elements to backprop into, no matter how many times you may traverse the data set. Indeed, the backpropagation window that each element receives is equal to imod\u200610 where i is the element\u2019s index. This is data inefficient, preventing $\\frac{1}{10}$ of the data set from ever being able to improve itself in a recurrent fashion, and resulting in $\\frac{8}{10}$ of the remaining elements receiving only a partial backpropagation window compared to the full possible backpropagation window of length 10. To prevent such inefficient data usage, we randomly select the sequence length for the forward and backward pass in two steps. First, we select the base sequence length to be seq with probability p and $\\frac{\\text{seq}}{2}$ with probability 1\u2005\u2212\u2005p, where p is a high value approaching 1. This spreads the starting point for the BPTT window beyond the base sequence length. We then select the sequence length according to \ud835\udca9(seq,s), where seq is the base sequence length and s is the standard deviation. This jitters the starting point such that it doesn\u2019t always fall on a specific word divisible by seq or $\\frac{\\text{seq}}{2}$. From these, the sequence length more efficiently uses the data set, ensuring that when given enough epochs all the elements in the data set experience a full BPTT window, while ensuring the average sequence length remains around the base sequence length for computational efficiency. During training, we rescale the learning rate depending on the length of the resulting sequence compared to the original specified sequence length. The rescaling step is necessary as sampling arbitrary sequence lengths with a fixed learning rate favors short sequences over longer ones. This linear scaling rule has been noted as important for training large scale minibatch SGD without loss of accuracy (Goyal et\u00a0al., 2017) and is a component of unbiased truncated backpropagation through time (Tallec & Ollivier, 2017).