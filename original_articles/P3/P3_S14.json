We employ three types of regularization during training: Residual Dropout We apply dropout (srivastava2014dropout, ) to the output of each sub-layer, before it is added to the sub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the positional encodings in both the encoder and decoder stacks. For the base model, we use a rate of P_(drop)\u2004=\u20040.1. Attention Dropout Query to key attentions are structurally similar to hidden-to-hidden weights in a feed-forward network, albeit across positions. The softmax activations yielding attention weights can then be seen as the analogue of hidden layer activations. A natural possibility is to extend dropout (srivastava2014dropout, ) to attention. We implement attention dropout by dropping out attention weights as,   -- ------------------------------------------------------------------------------------- --      $${{Attention}{(Q,K,V)}} = {{dropout}{({{softmax}{(\\frac{QK^{T}}{\\sqrt{d}})}})}V}$$    In addition to residual dropout, we found attention dropout to be beneficial for our parsing experiments. Label Smoothing During training, we employed label smoothing of value \u03f5_(ls)\u2004=\u20040.1 (DBLP:journals/corr/SzegedyVISW15, ). This hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.