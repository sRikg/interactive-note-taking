Fine-tuning models pre-trained on ImageNet\u00a0(Deng et\u00a0al., 2009) is ubiquitous when building image recognition models\u00a0(Yosinski et\u00a0al., 2014; Huh et\u00a0al., 2016). This technique attains state-of-the-art performance on many vision tasks, including classification\u00a0(Kornblith et\u00a0al., 2018), fine-grained classifcation\u00a0(Hermans et\u00a0al., 2017), segmentation\u00a0(Long et\u00a0al., 2015), and detection\u00a0(Girshick et\u00a0al., 2014). In vision, convolutional adapter modules have been studied\u00a0(Rebuffi et\u00a0al., 2017, 2018; Rosenfeld & Tsotsos, 2018). These works perform incremental learning in multiple domains by adding small convolutional layers to a ResNet\u00a0(He et\u00a0al., 2016) or VGG net\u00a0(Simonyan & Zisserman, 2014). Adapter size is limited using 1\u2005\u00d7\u20051 convolutions, whilst the original networks typically use 3\u2005\u00d7\u20053. This yields 11% increase in overall model size per task. Since the kernel size cannot be further reduced other weight compression techniques must be used to attain further savings. Our bottleneck adapters can be much smaller, and still perform well.