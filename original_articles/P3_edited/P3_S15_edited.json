"Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the English-to-German and English-to-French newstest2014 tests at a fraction of the training cost.   -------------------------------------------------------------- ------- ------- ----------------------- ------------   Model                                                          BLEU            Training Cost (FLOPs)                                                                     EN-DE   EN-FR   EN-DE                   EN-FR   ByteNet (NalBytenet2017, )                                     23.75                                      Deep-Att + PosUnk (DBLP:journals/corr/ZhouCWLX16, )                    39.2                            1.0\u2005\u22c5\u200510\u00b2\u2070   GNMT + RL (wu2016google, )                                     24.6    39.92   2.3\u2005\u22c5\u200510\u00b9\u2079              1.4\u2005\u22c5\u200510\u00b2\u2070   ConvS2S (JonasFaceNet2017, )                                   25.16   40.46   9.6\u2005\u22c5\u200510\u00b9\u2078              1.5\u2005\u22c5\u200510\u00b2\u2070   MoE (shazeer2017outrageously, )                                26.03   40.56   2.0\u2005\u22c5\u200510\u00b9\u2079              1.2\u2005\u22c5\u200510\u00b2\u2070   Deep-Att + PosUnk Ensemble (DBLP:journals/corr/ZhouCWLX16, )           40.4                            8.0\u2005\u22c5\u200510\u00b2\u2070   GNMT + RL Ensemble (wu2016google, )                            26.30   41.16   1.8\u2005\u22c5\u200510\u00b2\u2070              1.1\u2005\u22c5\u200510\u00b2\u00b9   ConvS2S Ensemble (JonasFaceNet2017, )                          26.36   41.29   7.7\u2005\u22c5\u200510\u00b9\u2079              1.2\u2005\u22c5\u200510\u00b2\u00b9   Transformer (base model)                                       27.3    38.1    3.3\u2005\u22c5\u200510\u00b9\u2078                 Transformer (big)                                              28.4    41.0    2.3\u2005\u22c5\u200510\u00b9\u2079               On the WMT 2014 English-to-German translation task, Our big transformer model (Transformer (big) in Table\u00a02) outperforms the best previously reported models (including ensembles) by more than 2.0 BLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is listed in the bottom line of Table\u00a03. Training took 3.5 days on 8 P100 GPUs. Even our base model surpasses all previously published models and ensembles, at a fraction of the training cost of any of the previous best models. On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0, outperforming all of the previously published single models, at less than 1/4 the training cost of the previous state-of-the-art model. The Transformer (big) model trained for English-to-French used dropout rate P_(drop)\u2004=\u20040.1, instead of 0.3. For the base models, we used a single model obtained by averaging the last 5 checkpoints, which were written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We used beam search with a beam size of 4 and length penalty \u03b1\u2004=\u20040.6 (wu2016google, ). These hyperparameters were chosen after experimentation on the development set. We set the maximum output length during inference to input length + 50, but terminate early when possible (wu2016google, ). Table 2 summarizes our results and compares our translation quality and training costs to other model architectures from the literature. We estimate the number of floating point operations used to train a model by multiplying the training time, the number of GPUs used, and an estimate of the sustained single-precision floating-point capacity of each GPU \u00b2\u00b22We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.."
